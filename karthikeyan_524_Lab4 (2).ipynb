{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMbnTakkRQEF3qQPzX0ASLe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/himanshuchrist/LLM/blob/main/Himanshu_520_Lab4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load the IMDb Dataset"
      ],
      "metadata": {
        "id": "K2nbdwVWyq7Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "SE_syjyaMTiD"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "dataset=load_dataset('imdb')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Take equal ratio of positive and negative reviews"
      ],
      "metadata": {
        "id": "5fIzRsFYy2ri"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "postive = [x for x in dataset['train'] if x['label'] == 1][:2500]\n",
        "negative = [x for x in dataset['train'] if x['label'] == 0][:2500]\n",
        "train_dataset = postive + negative\n",
        "random.shuffle(train_dataset)\n",
        "positive_test = [x for x in dataset['test'] if x['label'] == 1][:2500]\n",
        "negative_test = [x for x in dataset['test'] if x['label'] == 0][:2500]\n",
        "test_dataset = positive_test + negative_test\n",
        "random.shuffle(test_dataset)"
      ],
      "metadata": {
        "id": "J8hMiRxqTijY"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading Tokenizer and BERT model"
      ],
      "metadata": {
        "id": "z1kNmia6zD62"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
        "tokenizer=BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model=TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KaseIzVM46U",
        "outputId": "d8761ea4-6c2a-4993-8bec-7a1819325b40"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
            "\n",
            "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Defining Train and Test data"
      ],
      "metadata": {
        "id": "gZewNgUtzTxD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_texts = [x['text'] for x in train_dataset]\n",
        "train_labels = [x['label'] for x in train_dataset]\n",
        "test_texts = [x['text'] for x in test_dataset]\n",
        "test_labels = [x['label'] for x in test_dataset]"
      ],
      "metadata": {
        "id": "E8AhtEzBuQG8"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizing train and test test"
      ],
      "metadata": {
        "id": "wNAT3Az-zY_0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "train_encodings=tokenizer(train_texts, truncation=True, padding=True, max_length=128)\n",
        "test_encodings=tokenizer(test_texts, truncation=True, padding=True, max_length=128)"
      ],
      "metadata": {
        "id": "cDKeeY3fOu2t"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mapping train and test to labels"
      ],
      "metadata": {
        "id": "WoGQGWIKzcms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset=tf.data.Dataset.from_tensor_slices((dict(train_encodings), train_labels))\n",
        "test_dataset=tf.data.Dataset.from_tensor_slices((dict(test_encodings), test_labels))\n",
        "train_dataset=train_dataset.shuffle(1000).batch(8).prefetch(tf.data.AUTOTUNE)\n",
        "test_dataset=test_dataset.batch(8).prefetch(tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "ZGWcly0GQLht"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compiling the model"
      ],
      "metadata": {
        "id": "MD8mofiDzihm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
        "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "sUs1QlUSRaTt"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fitting the model"
      ],
      "metadata": {
        "id": "LfUgs_tdzl1H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_dataset, epochs=3, validation_data=test_dataset)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE0ZX6BRReCy",
        "outputId": "0eb82219-f08e-43a4-b535-d88b426b7362"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "625/625 [==============================] - 267s 331ms/step - loss: 0.5661 - accuracy: 0.6984 - val_loss: 0.3398 - val_accuracy: 0.8564\n",
            "Epoch 2/3\n",
            "625/625 [==============================] - 198s 317ms/step - loss: 0.2577 - accuracy: 0.8938 - val_loss: 0.3479 - val_accuracy: 0.8642\n",
            "Epoch 3/3\n",
            "625/625 [==============================] - 200s 320ms/step - loss: 0.1160 - accuracy: 0.9582 - val_loss: 0.4610 - val_accuracy: 0.8564\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf_keras.src.callbacks.History at 0x7d06882f0d00>"
            ]
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the Accuracy"
      ],
      "metadata": {
        "id": "HkBC85gqzoPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(test_dataset)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74Gy9hjZRhxN",
        "outputId": "53b9e69d-0933-48f6-a176-83f655f0f8ff"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "625/625 [==============================] - 51s 82ms/step - loss: 0.4610 - accuracy: 0.8564\n",
            "Test Accuracy: 0.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentiment Prediction function"
      ],
      "metadata": {
        "id": "XRsYrALhzqeg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(text):\n",
        "    inputs = tokenizer(text, return_tensors=\"tf\", truncation=True, padding=True, max_length=128)\n",
        "    outputs = model(inputs)\n",
        "    logits = outputs.logits\n",
        "    predictions = tf.nn.softmax(logits, axis=-1)\n",
        "    sentiment = tf.argmax(predictions, axis=1).numpy()[0]\n",
        "    return sentiment"
      ],
      "metadata": {
        "id": "BKu67_YWTTl7"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Predicting"
      ],
      "metadata": {
        "id": "yWZr75W_zune"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = input(\"Enter text for sentiment analysis: \")\n",
        "sentiment = predict_sentiment(text)\n",
        "sentiment_label = \"Positive\" if sentiment == 1 else \"Negative\"\n",
        "print(f\"Sentiment: {sentiment_label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d67Vj-rNjOic",
        "outputId": "cbd96a11-6aaf-483e-b118-0085883d3e1e"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter text for sentiment analysis: this is a good example of bad movie\n",
            "Sentiment: Negative\n"
          ]
        }
      ]
    }
  ]
}