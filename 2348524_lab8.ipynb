{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30356,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import tensorflow as tf\nfrom transformers import TFAutoModel, AutoTokenizer\nfrom datasets import load_dataset","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:00.532838Z","iopub.execute_input":"2024-07-25T13:50:00.533285Z","iopub.status.idle":"2024-07-25T13:50:00.538757Z","shell.execute_reply.started":"2024-07-25T13:50:00.533250Z","shell.execute_reply":"2024-07-25T13:50:00.537678Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"model = TFAutoModel.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:02.982459Z","iopub.execute_input":"2024-07-25T13:50:02.982858Z","iopub.status.idle":"2024-07-25T13:50:04.509414Z","shell.execute_reply.started":"2024-07-25T13:50:02.982826Z","shell.execute_reply":"2024-07-25T13:50:04.508615Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stderr","text":"Some layers from the model checkpoint at bert-base-uncased were not used when initializing TFBertModel: ['nsp___cls', 'mlm___cls']\n- This IS expected if you are initializing TFBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing TFBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nAll the layers of TFBertModel were initialized from the model checkpoint at bert-base-uncased.\nIf your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n","output_type":"stream"}]},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:04.512125Z","iopub.execute_input":"2024-07-25T13:50:04.512621Z","iopub.status.idle":"2024-07-25T13:50:06.723058Z","shell.execute_reply.started":"2024-07-25T13:50:04.512577Z","shell.execute_reply":"2024-07-25T13:50:06.722224Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"inputs = tokenizer(['Hello world', 'Hi how are you'], padding=True, truncation=True,\n                  return_tensors='tf')\ninputs","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:06.724278Z","iopub.execute_input":"2024-07-25T13:50:06.724601Z","iopub.status.idle":"2024-07-25T13:50:06.733170Z","shell.execute_reply.started":"2024-07-25T13:50:06.724571Z","shell.execute_reply":"2024-07-25T13:50:06.732235Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"{'input_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[ 101, 7592, 2088,  102,    0,    0],\n       [ 101, 7632, 2129, 2024, 2017,  102]], dtype=int32)>, 'token_type_ids': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[0, 0, 0, 0, 0, 0],\n       [0, 0, 0, 0, 0, 0]], dtype=int32)>, 'attention_mask': <tf.Tensor: shape=(2, 6), dtype=int32, numpy=\narray([[1, 1, 1, 1, 0, 0],\n       [1, 1, 1, 1, 1, 1]], dtype=int32)>}"},"metadata":{}}]},{"cell_type":"code","source":"output = model(inputs)\noutput","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:06.734425Z","iopub.execute_input":"2024-07-25T13:50:06.734723Z","iopub.status.idle":"2024-07-25T13:50:06.852315Z","shell.execute_reply.started":"2024-07-25T13:50:06.734695Z","shell.execute_reply":"2024-07-25T13:50:06.851297Z"},"trusted":true},"execution_count":13,"outputs":[{"execution_count":13,"output_type":"execute_result","data":{"text/plain":"TFBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=<tf.Tensor: shape=(2, 6, 768), dtype=float32, numpy=\narray([[[-0.16888332,  0.13606355, -0.13940018, ..., -0.6251125 ,\n          0.05217262,  0.36714536],\n        [-0.3632745 ,  0.14121903,  0.8799885 , ...,  0.10433032,\n          0.2887578 ,  0.37267894],\n        [-0.69859415, -0.69879794,  0.06450251, ..., -0.22103661,\n          0.00986893, -0.5939796 ],\n        [ 0.83098257,  0.12366717, -0.15119013, ...,  0.10309545,\n         -0.67792666, -0.26285172],\n        [-0.40266633, -0.01928236,  0.5732502 , ..., -0.20656842,\n          0.02338582,  0.20126349],\n        [-0.6228408 , -0.27453488,  0.1811763 , ..., -0.12944865,\n         -0.03839079, -0.05733156]],\n\n       [[ 0.09286558, -0.02636361, -0.12239343, ..., -0.21063566,\n          0.17386371,  0.17250973],\n        [ 0.40742022, -0.05930945,  0.55234593, ..., -0.6790563 ,\n          0.6555748 , -0.2945646 ],\n        [-0.21155298, -0.6858643 , -0.46280792, ...,  0.15278494,\n          0.59774226, -0.9102001 ],\n        [ 0.3992125 , -1.3207804 , -0.08008753, ..., -0.32125378,\n          0.25572804, -0.57804394],\n        [-0.07565154, -1.3393834 ,  0.18162948, ...,  0.07461128,\n          0.40318406, -0.7079987 ],\n        [ 0.5988934 , -0.28409335, -0.34899247, ...,  0.30420092,\n         -0.4367556 , -0.20969652]]], dtype=float32)>, pooler_output=<tf.Tensor: shape=(2, 768), dtype=float32, numpy=\narray([[-0.90615326, -0.31115308, -0.6216535 , ..., -0.30575195,\n        -0.64009386,  0.91661745],\n       [-0.930967  , -0.3380703 , -0.62161595, ..., -0.44018963,\n        -0.68128854,  0.9348898 ]], dtype=float32)>, past_key_values=None, hidden_states=None, attentions=None, cross_attentions=None)"},"metadata":{}}]},{"cell_type":"code","source":"emotions = load_dataset('SetFit/emotion')","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:06.854696Z","iopub.execute_input":"2024-07-25T13:50:06.854992Z","iopub.status.idle":"2024-07-25T13:50:08.243420Z","shell.execute_reply.started":"2024-07-25T13:50:06.854964Z","shell.execute_reply":"2024-07-25T13:50:08.242539Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"03b1e63043044176a1ee13b5f86416e9"}},"metadata":{}}]},{"cell_type":"code","source":"emotions","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:08.244590Z","iopub.execute_input":"2024-07-25T13:50:08.244861Z","iopub.status.idle":"2024-07-25T13:50:08.251521Z","shell.execute_reply.started":"2024-07-25T13:50:08.244835Z","shell.execute_reply":"2024-07-25T13:50:08.250432Z"},"trusted":true},"execution_count":15,"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"def tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:08.252838Z","iopub.execute_input":"2024-07-25T13:50:08.253133Z","iopub.status.idle":"2024-07-25T13:50:08.258885Z","shell.execute_reply.started":"2024-07-25T13:50:08.253107Z","shell.execute_reply":"2024-07-25T13:50:08.257879Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:08.260027Z","iopub.execute_input":"2024-07-25T13:50:08.260325Z","iopub.status.idle":"2024-07-25T13:50:10.828693Z","shell.execute_reply.started":"2024-07-25T13:50:08.260299Z","shell.execute_reply":"2024-07-25T13:50:10.827890Z"},"trusted":true},"execution_count":17,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1e2e4512e004ad1870254fad58fa204"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8ae71abcff1e4df798697bb8790858bc"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c98c238e1e3d4caa92c2fa0e897b46b8"}},"metadata":{}}]},{"cell_type":"code","source":"emotions_encoded","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:10.829896Z","iopub.execute_input":"2024-07-25T13:50:10.830279Z","iopub.status.idle":"2024-07-25T13:50:10.837329Z","shell.execute_reply.started":"2024-07-25T13:50:10.830247Z","shell.execute_reply":"2024-07-25T13:50:10.836367Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text', 'input_ids', 'token_type_ids', 'attention_mask'],\n        num_rows: 2000\n    })\n})"},"metadata":{}}]},{"cell_type":"code","source":"# setting 'input_ids', 'attention_mask', 'token_type_ids', and 'label'\n# to the tensorflow format. Now if you access this dataset you will get these\n# columns in `tf.Tensor` format\n\nemotions_encoded.set_format('tf', \n                            columns=['input_ids', 'attention_mask', 'token_type_ids', 'label'])\n\n# setting BATCH_SIZE to 64.\nBATCH_SIZE = 64\n\ndef order(inp):\n    '''\n    This function will group all the inputs of BERT\n    into a single dictionary and then output it with\n    labels.\n    '''\n    data = list(inp.values())\n    return {\n        'input_ids': data[1],\n        'attention_mask': data[2],\n        'token_type_ids': data[3]\n    }, data[0]\n\n# converting train split of `emotions_encoded` to tensorflow format\ntrain_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['train'][:])\n# set batch_size and shuffle\ntrain_dataset = train_dataset.batch(BATCH_SIZE).shuffle(1000)\n# map the `order` function\ntrain_dataset = train_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)\n\n# ... doing the same for test set ...\ntest_dataset = tf.data.Dataset.from_tensor_slices(emotions_encoded['test'][:])\ntest_dataset = test_dataset.batch(BATCH_SIZE)\ntest_dataset = test_dataset.map(order, num_parallel_calls=tf.data.AUTOTUNE)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:10.838778Z","iopub.execute_input":"2024-07-25T13:50:10.839436Z","iopub.status.idle":"2024-07-25T13:50:11.373607Z","shell.execute_reply.started":"2024-07-25T13:50:10.839394Z","shell.execute_reply":"2024-07-25T13:50:11.372800Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"inp, out = next(iter(train_dataset)) # a batch from train_dataset\nprint(inp, '\\n\\n', out)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:11.374764Z","iopub.execute_input":"2024-07-25T13:50:11.375060Z","iopub.status.idle":"2024-07-25T13:50:11.516894Z","shell.execute_reply.started":"2024-07-25T13:50:11.375031Z","shell.execute_reply":"2024-07-25T13:50:11.515856Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"{'input_ids': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[  101,  4921,  2063, ...,     0,     0,     0],\n       [  101,  1045,  2318, ...,     0,     0,     0],\n       [  101,  1045,  6181, ...,     0,     0,     0],\n       ...,\n       [  101,  1045,  2514, ...,     0,     0,     0],\n       [  101,  1045,  2788, ...,     0,     0,     0],\n       [  101, 10047,  3110, ...,     0,     0,     0]])>, 'attention_mask': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       ...,\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0],\n       [0, 0, 0, ..., 0, 0, 0]])>, 'token_type_ids': <tf.Tensor: shape=(64, 87), dtype=int64, numpy=\narray([[1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       ...,\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0],\n       [1, 1, 1, ..., 0, 0, 0]])>} \n\n tf.Tensor(\n[1 0 2 0 1 3 4 0 2 2 1 0 1 1 0 0 1 0 0 4 0 1 0 1 1 4 1 1 2 1 1 1 3 2 1 1 0\n 1 0 0 0 4 0 1 0 4 1 4 0 0 4 1 2 1 2 1 1 4 0 1 1 2 3 1], shape=(64,), dtype=int64)\n","output_type":"stream"}]},{"cell_type":"code","source":"class BERTForClassification(tf.keras.Model):\n    \n    def __init__(self, bert_model, num_classes):\n        super().__init__()\n        self.bert = bert_model\n        self.fc = tf.keras.layers.Dense(num_classes, activation='softmax')\n        \n    def call(self, inputs):\n        x = self.bert(inputs)[1]\n        return self.fc(x)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:11.518507Z","iopub.execute_input":"2024-07-25T13:50:11.518829Z","iopub.status.idle":"2024-07-25T13:50:11.524862Z","shell.execute_reply.started":"2024-07-25T13:50:11.518799Z","shell.execute_reply":"2024-07-25T13:50:11.523872Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"classifier = BERTForClassification(model, num_classes=6)\n\nclassifier.compile(\n    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n    metrics=['accuracy']\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:11.526403Z","iopub.execute_input":"2024-07-25T13:50:11.526816Z","iopub.status.idle":"2024-07-25T13:50:11.548310Z","shell.execute_reply.started":"2024-07-25T13:50:11.526777Z","shell.execute_reply":"2024-07-25T13:50:11.547389Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"# Function to classify new text\ndef classify_text(text):\n    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n    logits = classifier(inputs)\n    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n    return emotions['train'].features['label'].int2str(predicted_class)\n\n# Classify a new example\nnew_text = \"I feel great!\"\npredicted_emotion = classify_text(new_text)\nprint(f\"The predicted emotion for the text '{new_text}' is: {predicted_emotion}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:59:07.728056Z","iopub.status.idle":"2024-07-25T13:59:07.728440Z","shell.execute_reply.started":"2024-07-25T13:59:07.728233Z","shell.execute_reply":"2024-07-25T13:59:07.728250Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = classifier.fit(\n    train_dataset,\n    epochs=3\n)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:50:11.552138Z","iopub.execute_input":"2024-07-25T13:50:11.552719Z","iopub.status.idle":"2024-07-25T13:58:59.124513Z","shell.execute_reply.started":"2024-07-25T13:50:11.552690Z","shell.execute_reply":"2024-07-25T13:58:59.123489Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Epoch 1/3\n250/250 [==============================] - 173s 611ms/step - loss: 0.9506 - accuracy: 0.6482\nEpoch 2/3\n250/250 [==============================] - 153s 611ms/step - loss: 0.2397 - accuracy: 0.9124\nEpoch 3/3\n250/250 [==============================] - 153s 612ms/step - loss: 0.1473 - accuracy: 0.9407\n","output_type":"stream"}]},{"cell_type":"code","source":"classifier.evaluate(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2024-07-25T13:58:59.126034Z","iopub.execute_input":"2024-07-25T13:58:59.126355Z","iopub.status.idle":"2024-07-25T13:59:07.152433Z","shell.execute_reply.started":"2024-07-25T13:58:59.126326Z","shell.execute_reply":"2024-07-25T13:59:07.151450Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"32/32 [==============================] - 8s 164ms/step - loss: 0.1688 - accuracy: 0.9235\n","output_type":"stream"},{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[0.16878357529640198, 0.9235000014305115]"},"metadata":{}}]},{"cell_type":"code","source":"# Load the Emotion dataset\nemotions = load_dataset('SetFit/emotion')\n\n# Inspect the dataset structure and label features\nprint(emotions)\nprint(\"\\nLabel feature details for the 'train' split:\")\nprint(emotions['train'].features['label'])\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:09:19.637177Z","iopub.execute_input":"2024-07-25T14:09:19.637920Z","iopub.status.idle":"2024-07-25T14:09:21.129261Z","shell.execute_reply.started":"2024-07-25T14:09:19.637882Z","shell.execute_reply":"2024-07-25T14:09:21.128297Z"},"trusted":true},"execution_count":34,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"62b20fff255f4949a1f0c88c02ed8763"}},"metadata":{}},{"name":"stdout","text":"DatasetDict({\n    train: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 16000\n    })\n    test: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n    validation: Dataset({\n        features: ['text', 'label', 'label_text'],\n        num_rows: 2000\n    })\n})\n\nLabel feature details for the 'train' split:\nValue(dtype='int64', id=None)\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Load the Emotion dataset\nemotions = load_dataset('SetFit/emotion')\n\n# Access the 'train' split\ntrain_data = emotions['train']\n\n# Check the unique values in 'label'\nunique_labels = set(train_data['label'])\nprint(\"Unique numerical labels:\", unique_labels)\n\n# Check the unique values in 'label_text'\n# Ensure that 'label_text' exists in the dataset\nif 'label_text' in train_data.features:\n    unique_label_texts = set(train_data['label_text'])\n    print(\"Unique label texts:\", unique_label_texts)\nelse:\n    print(\"No 'label_text' feature found in the dataset.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:12:07.064141Z","iopub.execute_input":"2024-07-25T14:12:07.064557Z","iopub.status.idle":"2024-07-25T14:12:08.520221Z","shell.execute_reply.started":"2024-07-25T14:12:07.064520Z","shell.execute_reply":"2024-07-25T14:12:08.519284Z"},"trusted":true},"execution_count":36,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/3 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a2eb1a6f06d45448f131a4f8229fdca"}},"metadata":{}},{"name":"stdout","text":"Unique numerical labels: {0, 1, 2, 3, 4, 5}\nUnique label texts: {'anger', 'joy', 'surprise', 'fear', 'sadness', 'love'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create a label map from numerical labels to text labels\nlabel_map = {\n    0: 'anger',\n    1: 'joy',\n    2: 'surprise',\n    3: 'fear',\n    4: 'sadness',\n    5: 'love'\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:12:57.134516Z","iopub.execute_input":"2024-07-25T14:12:57.135497Z","iopub.status.idle":"2024-07-25T14:12:57.140777Z","shell.execute_reply.started":"2024-07-25T14:12:57.135453Z","shell.execute_reply":"2024-07-25T14:12:57.139622Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"\n# Function to classify new text\ndef classify_text(text):\n    inputs = tokenizer(text, padding=True, truncation=True, return_tensors='tf')\n    logits = classifier(inputs)\n    predicted_class = tf.argmax(logits, axis=1).numpy()[0]\n    label = label_map.get(predicted_class, \"Unknown\")\n    return label\n\n# Classify a new example\nnew_text = \"I feel great!\"\npredicted_emotion = classify_text(new_text)\nprint(f\"The predicted emotion for the text '{new_text}' is: {predicted_emotion}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-25T14:13:05.055611Z","iopub.execute_input":"2024-07-25T14:13:05.056008Z","iopub.status.idle":"2024-07-25T14:13:05.173097Z","shell.execute_reply.started":"2024-07-25T14:13:05.055975Z","shell.execute_reply":"2024-07-25T14:13:05.172031Z"},"trusted":true},"execution_count":38,"outputs":[{"name":"stdout","text":"The predicted emotion for the text 'I feel great!' is: joy\n","output_type":"stream"}]}]}